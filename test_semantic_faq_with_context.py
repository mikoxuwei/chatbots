
import json
import os
from dotenv import load_dotenv
import google.generativeai as genai

# === è¼‰å…¥ API é‡‘é‘° ===
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model_gemini = genai.GenerativeModel(model_name="gemini-1.5-flash")

# === FAQ è¼‰å…¥ ===
with open("faq2.json", "r", encoding="utf-8") as f:
    faq_data = json.load(f)["faq"]

# === å°è©±æ­·å²ç´€éŒ„ ===
dialog_history = []

# Gemini è™•ç† FAQ æˆ–ç”Ÿæˆå›ç­”
def get_semantic_faq_or_reply(user_input):
    try:
        # å»ºæ§‹ FAQ å€å¡Š
        faq_text_block = "\n".join([
            f"Q{i+1}: {item['question']}\nA{i+1}: {item['answer']}" 
            for i, item in enumerate(faq_data)
        ])

        # æ•´ç†å°è©±æ­·å²ï¼ˆæœ€å¤šä¿ç•™3è¼ªï¼‰
        history_text = "\n".join([f"ä½¿ç”¨è€…ï¼š{q}\nå®¢æœï¼š{a}" for q, a in dialog_history[-3:]])

        prompt = f"""
            ä½ æ˜¯ã€Œæ¯›èµ·ä¾†æ‰¾å®¶ã€çš„å°ˆæ¥­å®¢æœäººå“¡ï¼Œè«‹ä¾ç…§ FAQ æ±ºå®šæ˜¯å¦èƒ½ç›´æ¥å›ç­”ä½¿ç”¨è€…å•é¡Œã€‚
            å¦‚æœæ‰¾åˆ°æœ€æ¥è¿‘çš„ FAQ å•é¡Œï¼Œå°±ç›´æ¥å›è¦†è©²å•é¡Œçš„ç­”æ¡ˆï¼ˆA#ï¼‰ï¼Œä¸éœ€èªªæ˜ä¾†è‡ª FAQã€‚
            è‹¥ FAQ ç„¡æ³•æ¶µè“‹ï¼Œè«‹æ ¹æ“šä¸‹åˆ—é™åˆ¶æ¢ä»¶ï¼Œè‡ªè¡Œä»¥ç¹é«”ä¸­æ–‡ç”Ÿæˆä¸€æ®µç°¡æ½”ã€æº«æš–ä¸”å…·é«”çš„å›ç­”ã€‚

            è«‹æ³¨æ„ï¼šè‹¥ä½¿ç”¨è€…çš„èªå¥ä¸å®Œæ•´ï¼ˆå¦‚ã€Œæˆ‘æƒ³ç”³è«‹ã€ã€ã€Œéœ€è¦æº–å‚™ä»€éº¼ã€ï¼‰ï¼Œè«‹æ ¹æ“šä¸Šä¸€è¼ªå°è©±ä¸»é¡Œé€²è¡Œåˆ¤æ–·ï¼Œå»¶çºŒå°è©±å…§å®¹é€²è¡Œå›æ‡‰ã€‚

            [å¸¸è¦‹å•é¡Œ FAQ]
            {faq_text_block}

            [å°è©±æ­·å²]
            {history_text}

            [ä½¿ç”¨è€…æå•]
            {user_input}

            å›ç­”é™åˆ¶ï¼š
            - åƒ…é™æ–¼ã€Œé ˜é¤Šå¯µç‰©ã€ã€ã€Œé£¼é¤Šèˆ‡ç…§é¡§ã€ã€ã€Œå¸¸è¦‹ç–¾ç—…ã€ã€ã€Œç–«è‹—èˆ‡é˜²ç–«ã€ã€ã€Œé£¼ä¸»è²¬ä»»ã€ã€ã€Œå¯µç‰©ç”¨å“å»ºè­°ã€ç›¸é—œä¸»é¡Œ
            - è‹¥æåŠæƒ³é ˜é¤Šçš„å‹•ç‰©ï¼Œè«‹æé†’å‰å¾€ã€Œæ¯›èµ·ä¾†æ‰¾å®¶ã€å®˜ç¶²æŸ¥è©¢å¯é ˜é¤Šå“ç¨®ï¼ˆåƒ…é™è²“ã€ç‹—ã€å…”å­ã€å¤©ç«ºé¼ ã€å€‰é¼ ï¼‰
            - è‹¥æåŠç”¨å“ï¼Œå¯æ¨è–¦å•†å“ï¼Œä¸¦åŠ ä¸Šã€Œè‹¥ä¸ç¢ºå®šä¹Ÿæ­¡è¿åˆ°ç¾å ´åƒè§€ï¼Œæœƒæœ‰å°ˆäººç‚ºæ‚¨ä»‹ç´¹ã€
            - å›è¦†æ™‚åªå›ç­”èˆ‡å•é¡Œæœ€ç›¸é—œçš„ä¸€æ®µå…§å®¹ï¼Œä¸éœ€ä¸€æ¬¡èªªæ˜å…¨éƒ¨è³‡è¨Š
            """
        response = model_gemini.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print("âš ï¸ Gemini å›è¦†éŒ¯èª¤ï¼š", e)
        return "ç›®å‰æœå‹™å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™"

# === æ¸¬è©¦ CLI ===
if __name__ == "__main__":
    print("ğŸ”¸ è«‹è¼¸å…¥å•é¡Œï¼ˆè¼¸å…¥ q é›¢é–‹ï¼‰ï¼š")
    while True:
        user_input = input("ğŸ§¡ è«‹è¼¸å…¥å•é¡Œï¼š").strip()
        if user_input.lower() == "q":
            break

        reply = get_semantic_faq_or_reply(user_input)
        dialog_history.append((user_input, reply))

        print("ğŸ’¬ å›è¦†å…§å®¹ï¼š")
        print(reply)
        print()
