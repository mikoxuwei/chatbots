import json
import jieba
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# è®€å– FAQ
with open("faq2.json", "r", encoding="utf-8") as f:
    faq_data = json.load(f)["faq"]

faq_questions = [item["question"] for item in faq_data]
faq_answers = [item["answer"] for item in faq_data]

# åˆå§‹åŒ–èªæ„æ¨¡å‹
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
faq_embeddings = model.encode(faq_questions)

def search_faq_semantic(user_input, threshold=0.6):
    input_embedding = model.encode([user_input])
    similarities = cosine_similarity(input_embedding, faq_embeddings)[0]
    best_idx = similarities.argmax()
    if similarities[best_idx] >= threshold:
        return faq_answers[best_idx]
    return "ï¼ˆæ‰¾ä¸åˆ°ç¬¦åˆçš„ FAQï¼Œè«‹æ”¹å•å…¶ä»–å•é¡Œï¼‰"

# æ¸¬è©¦ç”¨äº’å‹•ä»‹é¢
print("ğŸ¾ æ­¡è¿ä¾†åˆ°ã€æ¯›èµ·ä¾†æ‰¾å®¶ã€å¸¸è¦‹å•ç­”ç³»çµ±ï¼Œè«‹è¼¸å…¥å•é¡Œï¼ˆè¼¸å…¥ 'exit' é›¢é–‹ï¼‰ï¼š")
while True:
    query = input("ğŸ§¡ è«‹è¼¸å…¥å•é¡Œï¼š").strip()
    if query.lower() == 'exit':
        break
    reply = search_faq_semantic(query)
    print(f"ğŸ’¬ å›è¦†å…§å®¹ï¼š{reply}\n")