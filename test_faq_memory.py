## geminiåˆ¤æ–·faqæˆ–ç”Ÿæˆå›ç­”ï¼ŒåŠ ä¸Šå„²å­˜è¨˜æ†¶
import json
import os
from dotenv import load_dotenv
import google.generativeai as genai

# === è¼‰å…¥ API é‡‘é‘° ===
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model_gemini = genai.GenerativeModel(model_name="gemini-1.5-flash")

# === FAQ è¼‰å…¥ ===
with open("faq2.json", "r", encoding="utf-8") as f:
    faq_data = json.load(f)["faq"]

# === åˆå§‹åŒ–å°è©±æ­·å² ===
conversation_history = []

# Gemini è™•ç† FAQ æˆ–ç”Ÿæˆå›ç­”
def get_semantic_faq_or_reply(user_input, history=None, max_history_turns=3):
    try:
        faq_text_block = "\n".join([
            f"Q{i+1}: {item['question']}\nA{i+1}: {item['answer']}" 
            for i, item in enumerate(faq_data)
        ])

        # æ­·å²å°è©±å…§å®¹ï¼ˆæœ€å¤šå›é¡§ n ç­†ï¼‰
        history_block = ""
        if history:
            for turn in history[-max_history_turns:]:
                history_block += f"ä½¿ç”¨è€…ï¼š{turn['user']}\nå®¢æœï¼š{turn['bot']}\n"

        prompt = f"""
ä½ æ˜¯ã€Œæ¯›èµ·ä¾†æ‰¾å®¶ã€çš„å°ˆæ¥­å®¢æœäººå“¡ï¼Œè«‹ä¾ç…§ä»¥ä¸‹ FAQ åˆ¤æ–·æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”ä½¿ç”¨è€…å•é¡Œã€‚

è‹¥æ‰¾åˆ°æœ€æ¥è¿‘çš„ FAQ å•é¡Œï¼Œå°±ç›´æ¥å›è¦†è©²å•é¡Œçš„å°æ‡‰ç­”æ¡ˆï¼ˆA#ï¼‰ï¼Œä¸éœ€è¦èªªæ˜ä¾†è‡ª FAQã€‚
è‹¥ FAQ ç„¡æ³•æ¶µè“‹ï¼Œè«‹æ ¹æ“šä¸‹æ–¹é™åˆ¶ï¼Œè‡ªè¡Œä»¥ç¹é«”ä¸­æ–‡ç”Ÿæˆç°¡æ½”ã€æº«æš–ä¸”å…·é«”çš„å›è¦†ã€‚

FAQï¼š
{faq_text_block}

å…ˆå‰å°è©±ç´€éŒ„å¦‚ä¸‹ï¼š
{history_block}

ä½¿ç”¨è€…å•é¡Œå¦‚ä¸‹ï¼š
ã€Œ{user_input}ã€

å›ç­”é™åˆ¶ï¼š
- åƒ…é™æ–¼ã€Œé ˜é¤Šå¯µç‰©ã€ã€ã€Œé£¼é¤Šèˆ‡ç…§é¡§ã€ã€ã€Œå¸¸è¦‹ç–¾ç—…ã€ã€ã€Œç–«è‹—èˆ‡é˜²ç–«ã€ã€ã€Œé£¼ä¸»è²¬ä»»ã€ã€ã€Œå¯µç‰©ç”¨å“å»ºè­°ã€ç­‰ä¸»é¡Œ
- è‹¥æåŠæƒ³é ˜é¤ŠæŸç¨®å¯µç‰©ï¼Œè«‹æé†’å‰å¾€ã€Œæ¯›èµ·ä¾†æ‰¾å®¶ã€å®˜ç¶²æŸ¥è©¢å¯é ˜é¤Šå“ç¨®ã€‚å¯è¢«é ˜é¤Šçš„å‹•ç‰©åŒ…å«ï¼šè²“ã€ç‹—ã€å…”å­ã€å¤©ç«ºé¼ ã€å€‰é¼ ï¼Œä¸åŒ…æ‹¬éæ³•æˆ–é‡ç”Ÿå‹•ç‰©å¦‚ç†Šã€è€è™ç­‰
- è‹¥æåŠç”¨å“ï¼Œå¯æ¨è–¦å•†å“ï¼Œä¸¦è£œå……ï¼šã€Œè‹¥ä¸ç¢ºå®šä¹Ÿæ­¡è¿åˆ°ç¾å ´åƒè§€ï¼Œæœƒæœ‰å°ˆäººç‚ºæ‚¨ä»‹ç´¹ã€
- å›è¦†æ™‚åªé‡å°å•é¡Œä¸­æœ€é‡è¦çš„ä¸»é¡Œå›ç­”ä¸€æ®µå…§å®¹ï¼Œé¿å…ä¸€æ¬¡èªªå®Œæ‰€æœ‰äº‹æƒ…
"""
        response = model_gemini.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print("âš ï¸ Gemini å›è¦†éŒ¯èª¤ï¼š", e)
        return "ç›®å‰æœå‹™å¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ ğŸ™"

# === æ¸¬è©¦ CLI ===
if __name__ == "__main__":
    print("ğŸ”¸ è«‹è¼¸å…¥å•é¡Œï¼ˆè¼¸å…¥ q é›¢é–‹ï¼‰ï¼š")
    while True:
        user_input = input("ğŸ§¡ è«‹è¼¸å…¥å•é¡Œï¼š").strip()
        if user_input.lower() == "q":
            break

        reply = get_semantic_faq_or_reply(user_input, history=conversation_history)
        print("ğŸ’¬ å›è¦†å…§å®¹ï¼š")
        print(reply + "\n")

        # å„²å­˜å°è©±æ­·å²
        conversation_history.append({
            "user": user_input,
            "bot": reply
        })